{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk pymystem3 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "import nltk\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database and getting posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/home/sh1ron/HSE/MLOps_pipeline/database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM posts\")\n",
    "posts = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM reactions\")\n",
    "reactions = cursor.fetchall()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "lemmatized_posts = []\n",
    "for post in posts:\n",
    "   text = re.sub('[^а-яА-ЯёЁ\\s]', '', post[2])\n",
    "   text = re.sub('\\s+', ' ', text)\n",
    "   text = text.lower()\n",
    "   \n",
    "   tokens = word_tokenize(text, language='russian')\n",
    "   lemmatized_tokens = [m.lemmatize(word)[0] if len(m.lemmatize(word)) > 0 else word for word in tokens if word not in stop_words]\n",
    "   lemmatized_posts.append(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most popular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in lemmatized_posts for item in sublist]\n",
    "\n",
    "word_counts = Counter(flat_list)\n",
    "top_words = word_counts.most_common(5)\n",
    "\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ten most popular emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = defaultdict(int)\n",
    "\n",
    "for reaction in reactions:\n",
    "    emoji = reaction[2]\n",
    "    if emoji is None:\n",
    "        emoji = '❤'\n",
    "    total_counts[emoji] += reaction[3]\n",
    "\n",
    "sorted_emojis = sorted(total_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_emojis = sorted_emojis[:10]\n",
    "\n",
    "print(top_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ten most popular posts for each of the most popular reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_reactions = {}\n",
    "for reaction in reactions:\n",
    "    post_id = reaction[1]\n",
    "    emoji = reaction[2]\n",
    "    count = reaction[3]\n",
    "    if post_id not in post_reactions:\n",
    "        post_reactions[post_id] = {}\n",
    "    post_reactions[post_id][emoji] = count\n",
    "\n",
    "for reaction in top_emojis:\n",
    "    emoji = reaction[0]\n",
    "    reaction_count = reaction[1]\n",
    "    \n",
    "    filtered_posts = []\n",
    "    for post in posts:\n",
    "        if post[0] in post_reactions and emoji in post_reactions[post[0]]:\n",
    "            filtered_posts.append((post, post_reactions[post[0]][emoji]))\n",
    "    \n",
    "    sorted_posts = sorted(filtered_posts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_10_posts = sorted_posts[:10]\n",
    "    \n",
    "    print(f\"Top 10 posts for reaction '{emoji}':\")\n",
    "    for post, reaction_count in top_10_posts:\n",
    "        print(f\"Post ID: {post[0]}, Reaction Count: {reaction_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for post in posts:\n",
    "    date_str = post[4]\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S') \n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity graph by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year_counts = defaultdict(int)\n",
    "\n",
    "for date in dates:\n",
    "    month_year_str = f\"{date.year}-{date.month:02}\"\n",
    "    month_year_counts[month_year_str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(month_year_counts.keys(), month_year_counts.values())\n",
    "plt.title('Activity per Month')\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Posts')\n",
    "\n",
    "plt.xticks(rotation=90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity graph by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_counts = defaultdict(int)\n",
    "\n",
    "for date in dates:\n",
    "    if date.year == 2022 and date.month == 2:\n",
    "        week_counts[date.isocalendar()[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(week_counts.keys(), week_counts.values())\n",
    "plt.title('Activity in February 2022')\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Posts')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity graph by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_counts = defaultdict(int)\n",
    "\n",
    "for date in dates:\n",
    "    if date.year == 2022 and date.month == 9:\n",
    "        day_counts[date.day] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(day_counts.keys(), day_counts.values())\n",
    "plt.title('Activity in September 2022')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number of Posts')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
